{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science__Numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Pearson's correlation $r(x,y)$\n",
    "<br>$$r(x,y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits_{i=1}^n (x_i - \\bar{x})^2 \\sum\\limits_{i=1}^n(y_i - \\bar{y})^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the pearson correlation between two vectors\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"Computes Pearson's correlation coefficient between vectors x and y.\"\"\"\n",
    "    \n",
    "    x_mean = np.mean(x)   # calculate x mean\n",
    "    y_mean = np.mean(y)   # calculate y mean\n",
    "    \n",
    "    x_dif = x - x_mean    # calculate the difference between each x and x mean\n",
    "    y_dif = y - y_mean    # calculate the difference between each y and y mean\n",
    "    \n",
    "    x_sse = np.sum(x_dif**2)  # calculate the sum of squared error for x\n",
    "    y_sse = np.sum(y_dif**2)  # calculate the sum of squared error for y\n",
    "    \n",
    "    denominator = np.sqrt(x_sse * y_sse)\n",
    "    nominator = np.sum(x_dif * y_dif)\n",
    "    \n",
    "    return nominator/denominator  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "n = 10                        # x and y are both NumPy arrays of size(1,ùëõ) \n",
    "x = np.random.random((1,10))  # create a 1*10 matrix with uniform(0,1) entries\n",
    "y = np.random.random((1,10))  \n",
    "\n",
    "# check my code\n",
    "np.round(pearson_correlation(x,y),6) == np.round(np.corrcoef(x,y)[0,1],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Pearson's Correlations inside a matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7339"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach_1\n",
    "def max_corr(n,m):\n",
    "    array = np.random.random((n,m)) \n",
    "    \"\"\"find maximum correlation between columns of (n,m) random uniform (0,1) array\"\"\"\n",
    "    \n",
    "    r_list = [] # creative a empty list to store the Pearson correlation coefficients for each of the m choose 2 pairs of columns\n",
    "    # use two for loops to control the indexs i and j in order to make m choose 2 times loops\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(i+1,m):\n",
    "            # calculate the Pearson correlation coefficients for array column i and j \n",
    "            r = round(np.corrcoef(array[:,i],array[:,j])[0,1], 4) \n",
    "            r_list.append(r) # add the results to the r_list \n",
    "            \n",
    "    return max(r_list) # return the maximum value of the Pearson correlation coefficients\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "max_corr(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach_2\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "def max_corr(n,m):\n",
    "    \"\"\"find maximum correlation between columns of (n,m) random uniform (0,1) array\"\"\"\n",
    "    array = np.random.random((n,m)) \n",
    "    correlations = np.zeros((m,m)) # make matrix to store correlations between columns\n",
    "    \n",
    "    for a in range(m):             # loop over columns\n",
    "        for b in range(m):\n",
    "            correlations[a,b] = np.corrcoef(array[:,a], array[:,b])[0,1] \n",
    "                             # find Pearson's correlation between columns\n",
    "                                                                         \n",
    "    return round(max(correlations[np.eye(m)==0]),2) # disregard correlations of columns with themselves \n",
    "                             # that is, ignore the \"1\" entries in the diagonal and find the max of the rest. \n",
    "\n",
    "max_corr(10,20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbor\n",
    "\n",
    "Recall, that Euclidean distance between two points is defined as \n",
    "<br><br>$$X=(x_1, x_2) \\mbox{ and} y=(y_1, y_2)$$\n",
    "<br>$$d_{\\mbox{Euclidean}} = \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pairwise Euclidean distances\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "# broadcast the arrays to find pair-wise distances btw any two points.\n",
    "X = np.random.randint(1,10,size = (10,2))\n",
    "X3d = X[:,np.newaxis,:] - X[np.newaxis,:] \n",
    "dist_squared = X3d**2\n",
    "\n",
    "# add the squared coordinate-wise difference\n",
    "sum_squared_dist = np.sum(dist_squared, axis = 2)  \n",
    "\n",
    "# take the squared root of the result\n",
    "dist_eucl = np.array([np.sqrt(xi) for xi in sum_squared_dist])                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 1],\n",
       "       [6, 7, 4],\n",
       "       [9, 1, 6],\n",
       "       [5, 8, 2],\n",
       "       [7, 1, 0],\n",
       "       [3, 8, 2],\n",
       "       [0, 1, 7],\n",
       "       [4, 0, 1],\n",
       "       [3, 5, 2],\n",
       "       [2, 6, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the three nearest neighbors of a point.\n",
    "# indexing the smallest three entries of each row\n",
    "neighbors = np.argsort(dist_eucl, axis = 1)                                                               \n",
    "near_neighbors = neighbors[ : ,1:4]\n",
    "near_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Covariance between vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def covariance(x, y):\n",
    "    \"\"\" Finds the covariance between vectors x and y\"\"\"\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    data = [(x[i] - x_mean) * (y[i] - y_mean) for i in range(len(x))]\n",
    "    return sum(data)/(len(data) - 1)\n",
    "\n",
    "import numpy as np\n",
    "x = np.random.random((10,1))\n",
    "y = np.random.random((10,1))\n",
    "np.round(covariance(x,y),6) == np.round(np.cov(x.T, y.T)[0,1],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Covariance matrix of matrix X\n",
    "Suppose that $X$ is a matrix with n rows and m columns. In statistics, these matrices arise freqently when we collect (numerical) data on m variables which are each observed on n independent individuals. Suppose we denote the columns of $X = (x_1, \\ldots, x_m)$. Then the covariance matrix of $X$ is defined as \n",
    "\n",
    "$$ \\mbox{Cov}(X) = \\left( \\begin{array}{cccc}\n",
    "Var(x_1) & Cov(x_1, x_2) & \\cdots & Cov(x_1, x_m) \\\\\n",
    "Cov(x_2, x_1) & Var(x_2) & \\cdots & Cov(x_2, x_m) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "Cov(x_m, x_1) & Cov(x_m, x_2) & \\cdots & Var(x_m) \n",
    "\\end{array} \\right) $$\n",
    "\n",
    "where Var($x_i$) is the sample variance of the entries in the $i^{th}$ column of $X$ and Cov($x_i, x_j$) ($i \\neq j$) is the sample covariance of the entries in columns $i$ and $j$. \n",
    "\n",
    "$$ Cov(x_i, x_j) = \\frac{1}{n-1}\\sum\\limits_{k=1}^n (x_{ki} - \\bar{x}_i)(x_{kj}-\\bar{x_j})$$\n",
    "\n",
    "That is, the covariance matrix is a square $m\\times m$ matrix whose diagonal entries are the sample variances of the columns of $X$ and whose off-diagonal entries are covariances between two columns of $X$, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach_1\n",
    "\n",
    "def covariance_matrix(X):\n",
    "    \"\"\" Finds the covariance matrix of (n,m) shaped array X\"\"\"\n",
    "    \n",
    "    n = len(X)                                # row number \n",
    "    column_means = np.mean(X, axis = 0)       # calculate the column means, column_means_shape=(1,m)\n",
    "    dif = X[np.newaxis,:,:] - column_means    # broadcast arrays and minus the column mean row-wise, dif.shape=(1,n,m)\n",
    "    dot_product = dif * dif.T                 # make transfer, dif.T.shape=(m,n,1), dot_product.shape=(m,m)\n",
    "    cov = np.sum(dot_product, axis = 1)/(n-1) # sum the dot_product row-wise and divide by n-1\n",
    "    return cov\n",
    "\n",
    "# check your work\n",
    "# or make up some other matrix for X \n",
    "X = np.random.random((5,3))  \n",
    "\n",
    "np.array_equal(np.round(np.cov(X.T),4), np.round(covariance_matrix(X),4))  \n",
    "# Numpy treats each row of array as a separate variable\n",
    "# again, we're rounding because your \"hand\" computation will differ slightly from NumPy's internal computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach_2\n",
    "\n",
    "def covariance_matrix(X):\n",
    "    \"\"\" Finds the covariance matrix of (n,m) shaped array X\"\"\"\n",
    "    \n",
    "    n = np.shape(X)[0]\n",
    "    m = np.shape(X)[1]\n",
    "    cov_matrix = np.zeros((m,m))  # make \"empty\" of floats to later store covariances in \n",
    "    for i in range(m):            # iterating over COLUMNS of X\n",
    "        for j in range(m):\n",
    "            cov_matrix[i,j] = (1/(n-1))*np.sum((X[:,i]-X[:,i].mean())*(X[:,j]-X[:,j].mean())) \n",
    "                                  # assemble covariance matrix\n",
    "    return cov_matrix\n",
    "    \n",
    "## check your work\n",
    "X = np.random.random((5,3))  # or make up some other matrix for X \n",
    "np.array_equal(np.round(np.cov(X.T),4), np.round(covariance_matrix(X),4)) \n",
    "# again, we're rounding because your \"hand\" computation will differ slightly from NumPy's internal computations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
